{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefb0dc1-b8f7-4c21-90e1-2c0ec5d95116",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Prep for Contrastive Learning\n",
    "\n",
    "Reference: \\\n",
    "https://github.com/jahuerta92/authorship-embeddings/blob/main/gather_data.ipynb \\\n",
    "https://github.com/jahuerta92/authorship-embeddings/blob/main/clean_data.ipynb \\\n",
    "https://github.com/LLNL/LUAR/blob/main/scripts\n",
    "\n",
    "Note: id denotes author_id rather than text_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f035508-dae7-4248-9dac-d21055983a9b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "CHUNK_SIZE = 512\n",
    "MODEL_TYPE = \"roberta-large\"\n",
    "FILE_PATH = '/data/baixiang/dataset/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d928da-e729-4c28-83af-d63cce53d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(row):\n",
    "    eid, values = row\n",
    "    input_ids = tokenizer(values.text).input_ids\n",
    "    chunked = [input_ids[chunk: chunk + CHUNK_SIZE] for chunk in range(0, len(input_ids), CHUNK_SIZE)]\n",
    "    decoded_chunked = tokenizer.batch_decode(chunked)\n",
    "    return pd.DataFrame({'id': [eid]*len(chunked), 'pretokenized_text': chunked, 'decoded_text': decoded_chunked})\n",
    "                         \n",
    "    \n",
    "def build_chunk_dataframe(text_data, metadata=None, cores=10):\n",
    "    with Pool(cores) as p:\n",
    "        chunks = list(tqdm(p.imap_unordered(split_data, text_data.iterrows()), total=len(text_data)))\n",
    "    if metadata is not None:\n",
    "        return pd.concat(chunks).merge(metadata, on='id')\n",
    "    else:\n",
    "        return pd.concat(chunks)\n",
    "\n",
    "    \n",
    "def clean_non_unique(data):\n",
    "    nunique_ids = (data.id.value_counts() > 1)\n",
    "    nunique_ids = nunique_ids[nunique_ids].index\n",
    "    return data[data.id.isin(nunique_ids)]\n",
    "\n",
    "\n",
    "def rm_duplicate_fn(df, column_ls):\n",
    "    print('# duplicates:', df.text.duplicated().sum(), 'sanity check:', df.shape[0] - len(set(df.text)))\n",
    "    print('Before removing duplicates, df.shape:', df.shape)\n",
    "    df = df.drop_duplicates(subset=column_ls, keep='first').reset_index(drop=True)\n",
    "    print('New df.shape:', df.shape)\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_test_split_by_author(df, test_size=0.1, random_state=42):\n",
    "    unique_authors = df.id.unique()\n",
    "    in_test = np.random.choice(unique_authors, int(len(unique_authors) * test_size), replace=False)\n",
    "    return df[~df.id.isin(in_test)], df[df.id.isin(in_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfc3b07-161e-41eb-ad94-02e6e67417ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Blog\n",
    "https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0054563b-a6ef-47b8-98e9-0994e2618ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age    topic sign         date  \\\n",
       "0  2059027   male   15  Student  Leo  14,May,2004   \n",
       "1  2059027   male   15  Student  Leo  13,May,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_data = pd.read_csv(FILE_PATH+\"blogtext.csv\")\n",
    "blog_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c7d5f6-4982-438d-90e8-cf7999c0899d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog_0</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog_0</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog_0</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blog_0</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog_1</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681279</th>\n",
       "      <td>blog_19319</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  I could write some really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681280</th>\n",
       "      <td>blog_19319</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  'I have the second yeast i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681281</th>\n",
       "      <td>blog_19319</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  Your 'boyfriend' is fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681282</th>\n",
       "      <td>blog_19319</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan:    Just to clarify, I am as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681283</th>\n",
       "      <td>blog_19319</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Hey everybody...and Susan,  You might a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id gender  age              topic      sign          date  \\\n",
       "0           blog_0   male   15            Student       Leo   14,May,2004   \n",
       "1           blog_0   male   15            Student       Leo   13,May,2004   \n",
       "2           blog_0   male   15            Student       Leo   12,May,2004   \n",
       "3           blog_0   male   15            Student       Leo   12,May,2004   \n",
       "4           blog_1   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "...            ...    ...  ...                ...       ...           ...   \n",
       "681279  blog_19319   male   23            Student    Taurus  01,July,2004   \n",
       "681280  blog_19319   male   23            Student    Taurus  01,July,2004   \n",
       "681281  blog_19319   male   23            Student    Taurus  01,July,2004   \n",
       "681282  blog_19319   male   23            Student    Taurus  01,July,2004   \n",
       "681283  blog_19319   male   23            Student    Taurus  01,July,2004   \n",
       "\n",
       "                                                     text  \n",
       "0                  Info has been found (+/- 100 pages,...  \n",
       "1                  These are the team members:   Drewe...  \n",
       "2                  In het kader van kernfusie op aarde...  \n",
       "3                        testing!!!  testing!!!            \n",
       "4                    Thanks to Yahoo!'s Toolbar I can ...  \n",
       "...                                                   ...  \n",
       "681279         Dear Susan,  I could write some really ...  \n",
       "681280         Dear Susan,  'I have the second yeast i...  \n",
       "681281         Dear Susan,  Your 'boyfriend' is fuckin...  \n",
       "681282         Dear Susan:    Just to clarify, I am as...  \n",
       "681283         Hey everybody...and Susan,  You might a...  \n",
       "\n",
       "[681284 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace user id values with \"blog_n\" where n is a number beggining at 0\n",
    "n_values = len(blog_data.id.unique())\n",
    "author_mapping = {k: v for k, v in zip(blog_data.id.unique(), range(n_values))}\n",
    "blog_data['id'] = blog_data['id'].apply(lambda x: 'blog_' + str(author_mapping[x]))\n",
    "blog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28134615-5da3-4f0c-9402-bdbcaa8908f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19320, 611652)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(blog_data['id'])), len(np.unique(blog_data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de420329-1f9d-4215-ac60-7250c96af96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651906</th>\n",
       "      <td>blog_18413</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>14,June,2004</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651920</th>\n",
       "      <td>blog_18413</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>02,June,2004</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212416</th>\n",
       "      <td>blog_5943</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>01,August,2004</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212417</th>\n",
       "      <td>blog_5943</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>01,August,2004</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651889</th>\n",
       "      <td>blog_18413</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>11,May,2004</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471113</th>\n",
       "      <td>blog_13165</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>27,May,2004</td>\n",
       "      <td>People...I figured that Grellow would crumble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471107</th>\n",
       "      <td>blog_13165</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>31,May,2004</td>\n",
       "      <td>Today... I am with Sydney, and we decided to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471123</th>\n",
       "      <td>blog_13165</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>31,May,2004</td>\n",
       "      <td>Today... I am with Sydney, and we decided to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471120</th>\n",
       "      <td>blog_13165</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>26,May,2004</td>\n",
       "      <td>Tom Felton is the reason why everything wrong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471136</th>\n",
       "      <td>blog_13165</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>26,May,2004</td>\n",
       "      <td>Tom Felton is the reason why everything wrong...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6791 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id gender  age        topic         sign            date  \\\n",
       "651906  blog_18413   male   27   Technology       Taurus    14,June,2004   \n",
       "651920  blog_18413   male   27   Technology       Taurus    02,June,2004   \n",
       "212416   blog_5943   male   36  Advertising  Sagittarius  01,August,2004   \n",
       "212417   blog_5943   male   36  Advertising  Sagittarius  01,August,2004   \n",
       "651889  blog_18413   male   27   Technology       Taurus     11,May,2004   \n",
       "...            ...    ...  ...          ...          ...             ...   \n",
       "471113  blog_13165   male   14      Student  Sagittarius     27,May,2004   \n",
       "471107  blog_13165   male   14      Student  Sagittarius     31,May,2004   \n",
       "471123  blog_13165   male   14      Student  Sagittarius     31,May,2004   \n",
       "471120  blog_13165   male   14      Student  Sagittarius     26,May,2004   \n",
       "471136  blog_13165   male   14      Student  Sagittarius     26,May,2004   \n",
       "\n",
       "                                                     text  \n",
       "651906                                                     \n",
       "651920                                                     \n",
       "212416                                                     \n",
       "212417                                                     \n",
       "651889                                                     \n",
       "...                                                   ...  \n",
       "471113   People...I figured that Grellow would crumble...  \n",
       "471107   Today... I am with Sydney, and we decided to ...  \n",
       "471123   Today... I am with Sydney, and we decided to ...  \n",
       "471120   Tom Felton is the reason why everything wrong...  \n",
       "471136   Tom Felton is the reason why everything wrong...  \n",
       "\n",
       "[6791 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding and removing duplicate rows\n",
    "blog_data[blog_data[['id', 'text', 'date']].duplicated(keep=False)].sort_values('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f82cba-a4c4-4408-b650-2fe31b58bc4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicates: 69632 sanity check: 69632\n",
      "Before removing duplicates, df.shape: (681284, 7)\n",
      "New df.shape: (676598, 7)\n"
     ]
    }
   ],
   "source": [
    "blog_corpus = rm_duplicate_fn(blog_data, ['id', 'text', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "457859fe-ea41-43f4-9014-3606277f0137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>gender</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blog_0</th>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "      <td>Info has been found (+/- 100 pages, and 4.5 MB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_1</th>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>male</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can now 'capture'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_10</th>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>Even though I am exhausted after today, I must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_100</th>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "      <td>Hello again.  This is the offical No Action bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_1000</th>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "      <td>My 'band' got in its first fight tonight. most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9995</th>\n",
       "      <td>17</td>\n",
       "      <td>Communications-Media</td>\n",
       "      <td>male</td>\n",
       "      <td>Good morning folks,  How are me brothers and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9996</th>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>NEWater   Ok, that's just gross.   Another pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9997</th>\n",
       "      <td>26</td>\n",
       "      <td>Education</td>\n",
       "      <td>male</td>\n",
       "      <td>I love salsa. It's one of the greatest foods e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9998</th>\n",
       "      <td>13</td>\n",
       "      <td>Law</td>\n",
       "      <td>male</td>\n",
       "      <td>Hey all, This is Jared, this is my first post ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9999</th>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>On the underground in London, at rush hour, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age                 topic  gender  \\\n",
       "id                                             \n",
       "blog_0      15               Student    male   \n",
       "blog_1      33     InvestmentBanking    male   \n",
       "blog_10     25                indUnk  female   \n",
       "blog_100    26                indUnk    male   \n",
       "blog_1000   16               Student    male   \n",
       "...        ...                   ...     ...   \n",
       "blog_9995   17  Communications-Media    male   \n",
       "blog_9996   23                indUnk  female   \n",
       "blog_9997   26             Education    male   \n",
       "blog_9998   13                   Law    male   \n",
       "blog_9999   33                indUnk  female   \n",
       "\n",
       "                                                        text  \n",
       "id                                                            \n",
       "blog_0     Info has been found (+/- 100 pages, and 4.5 MB...  \n",
       "blog_1     Thanks to Yahoo!'s Toolbar I can now 'capture'...  \n",
       "blog_10    Even though I am exhausted after today, I must...  \n",
       "blog_100   Hello again.  This is the offical No Action bl...  \n",
       "blog_1000  My 'band' got in its first fight tonight. most...  \n",
       "...                                                      ...  \n",
       "blog_9995  Good morning folks,  How are me brothers and s...  \n",
       "blog_9996  NEWater   Ok, that's just gross.   Another pot...  \n",
       "blog_9997  I love salsa. It's one of the greatest foods e...  \n",
       "blog_9998  Hey all, This is Jared, this is my first post ...  \n",
       "blog_9999  On the underground in London, at rush hour, th...  \n",
       "\n",
       "[19320 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_corpus.text = blog_corpus.text.apply(lambda x: x.strip())\n",
    "clean_blog_corpus = blog_corpus[['id', 'text']].groupby(\"id\").agg(lambda x: '<\\s>'.join(x))\n",
    "meta_blog_corpus = blog_corpus[['id', 'age', 'topic', 'gender']].groupby(\"id\").agg(lambda x: list(x)[0])\n",
    "full_blog_corpus = meta_blog_corpus.merge(clean_blog_corpus, on='id')\n",
    "full_blog_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d33b5b6-5870-4bd6-80f0-1a2b8521d7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19320, 1), (19320, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_blog_corpus.shape, meta_blog_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dd418c8-cbac-4545-8505-f7f1135d1697",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8784f2e72d9419c85018cbc3a9cdd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1726 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3686 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5819 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2760 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5105 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (13806 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (11338 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (40825 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog_10</td>\n",
       "      <td>[0, 8170, 600, 38, 524, 17067, 71, 452, 6, 38,...</td>\n",
       "      <td>&lt;s&gt;Even though I am exhausted after today, I m...</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog_10</td>\n",
       "      <td>[216, 24, 4, 152, 7105, 16, 3680, 684, 25, 121...</td>\n",
       "      <td>know it. This hell is otherwise known as U Vi...</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog_10</td>\n",
       "      <td>[17027, 12, 560, 12, 1610, 18, 2850, 12179, 33...</td>\n",
       "      <td>groom-to-be's scrotal bling, but not the Fout...</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blog_100</td>\n",
       "      <td>[0, 31414, 456, 4, 1437, 152, 16, 5, 160, 3569...</td>\n",
       "      <td>&lt;s&gt;Hello again.  This is the offical No Action...</td>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog_100</td>\n",
       "      <td>[5, 7884, 20774, 29, 31, 14, 6, 25, 157, 25, 5...</td>\n",
       "      <td>the singalongs from that, as well as the mino...</td>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381429</th>\n",
       "      <td>blog_9996</td>\n",
       "      <td>[941, 187, 38, 437, 45, 10, 13853, 226, 14669,...</td>\n",
       "      <td>especially since I'm not a Lindsay Lohan fan....</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381430</th>\n",
       "      <td>blog_9996</td>\n",
       "      <td>[13137, 1437, 46471, 17860, 229, 5602, 8, 4077...</td>\n",
       "      <td>twins  urlLink Kami and Karli  have not been ...</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381431</th>\n",
       "      <td>blog_9996</td>\n",
       "      <td>[2600, 127, 7833, 5548, 255, 2747, 998, 35, 10...</td>\n",
       "      <td>reading my absolute favourite TAR website: Te...</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381432</th>\n",
       "      <td>blog_9996</td>\n",
       "      <td>[75, 29, 1437, 157, 6, 667, 66, 10, 92, 29618,...</td>\n",
       "      <td>'ts  well, trying out a new haircut and all i ...</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381433</th>\n",
       "      <td>blog_9996</td>\n",
       "      <td>[9, 143, 470, 12, 7078, 1012, 311, 4, 36, 2664...</td>\n",
       "      <td>of any American-made TV show. (Think Wheel of...</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381306 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                  pretokenized_text  \\\n",
       "0         blog_10  [0, 8170, 600, 38, 524, 17067, 71, 452, 6, 38,...   \n",
       "1         blog_10  [216, 24, 4, 152, 7105, 16, 3680, 684, 25, 121...   \n",
       "2         blog_10  [17027, 12, 560, 12, 1610, 18, 2850, 12179, 33...   \n",
       "3        blog_100  [0, 31414, 456, 4, 1437, 152, 16, 5, 160, 3569...   \n",
       "4        blog_100  [5, 7884, 20774, 29, 31, 14, 6, 25, 157, 25, 5...   \n",
       "...           ...                                                ...   \n",
       "381429  blog_9996  [941, 187, 38, 437, 45, 10, 13853, 226, 14669,...   \n",
       "381430  blog_9996  [13137, 1437, 46471, 17860, 229, 5602, 8, 4077...   \n",
       "381431  blog_9996  [2600, 127, 7833, 5548, 255, 2747, 998, 35, 10...   \n",
       "381432  blog_9996  [75, 29, 1437, 157, 6, 667, 66, 10, 92, 29618,...   \n",
       "381433  blog_9996  [9, 143, 470, 12, 7078, 1012, 311, 4, 36, 2664...   \n",
       "\n",
       "                                             decoded_text  age   topic  gender  \n",
       "0       <s>Even though I am exhausted after today, I m...   25  indUnk  female  \n",
       "1        know it. This hell is otherwise known as U Vi...   25  indUnk  female  \n",
       "2        groom-to-be's scrotal bling, but not the Fout...   25  indUnk  female  \n",
       "3       <s>Hello again.  This is the offical No Action...   26  indUnk    male  \n",
       "4        the singalongs from that, as well as the mino...   26  indUnk    male  \n",
       "...                                                   ...  ...     ...     ...  \n",
       "381429   especially since I'm not a Lindsay Lohan fan....   23  indUnk  female  \n",
       "381430   twins  urlLink Kami and Karli  have not been ...   23  indUnk  female  \n",
       "381431   reading my absolute favourite TAR website: Te...   23  indUnk  female  \n",
       "381432  'ts  well, trying out a new haircut and all i ...   23  indUnk  female  \n",
       "381433   of any American-made TV show. (Think Wheel of...   23  indUnk  female  \n",
       "\n",
       "[381306 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_blog_data = build_chunk_dataframe(full_blog_corpus, meta_blog_corpus)\n",
    "nunique_blog_data = clean_non_unique(chunked_blog_data)\n",
    "nunique_blog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44e22f0d-8e3d-4e48-b0ce-82490a1188d5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5819 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<s>Info has been found (+/- 100 pages, and 4.5 MB of.pdf files) Now i have to wait untill our team leader has processed it and learns html.<\\\\s>These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail<\\\\s>In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An H-Bomb (humorous!) Date: 7 Feb 1994 07:41:14 GMT Organization: The University of Western Australia  Original file dated 12th November 1990. Seemed to be a transcript of a 'Seven Days' article. Poorly formatted and corrupted. I have added the text between 'examine under a microscope' and'malleable, like gold,' as it was missing. If anyone has the full text, please distribute. I am not responsible for the accuracy of this information. Converted to HTML by Dionisio@InfiNet.com 11/13/98. (Did a little spell-checking and some minor edits too.) Stolen from  urlLink http://my.ohio.voyager.net/~dionisio/fun/m...own-h-bomb.html  and reformatted the HTML. It now validates to XHTML 1.0 Strict. How to Build an H-Bomb Making and owning an H-bomb is the kind of challenge real Americans seek. Who wants to be a passive victim of nuclear war when, with a little effort, you can be an active participant? Bomb shelters are for losers. Who wants to huddle together underground eating canned Spam? Winners want to push the button themselves. Making your own H-bomb is a big step in nuclear assertiveness training -- it's called Taking Charge. We're sure you'll enjoy the risks and the heady thrill of playing nuclear chicken. Introduction When the Feds clamped down on The Progressive magazine for attempting to publish an article on\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = full_blog_corpus.iloc[0].text\n",
    "input_ids = tokenizer(tmp).input_ids\n",
    "print(len(input_ids))\n",
    "[len(input_ids[chunk: chunk + CHUNK_SIZE]) for chunk in range(0, len(input_ids), CHUNK_SIZE)]\n",
    "tokenizer.decode(input_ids[:CHUNK_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df9b25ec-d5d1-4b8e-81c8-73892b5fdad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((681284, 7), (19320, 4), (381434, 6), (381306, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full_blog_corpus merges texts by authors, chunked_blog_data divide merged text into chunks of size 512\n",
    "# nunique_blog_data remove authors who have only 1 chunk\n",
    "blog_data.shape, full_blog_corpus.shape, chunked_blog_data.shape, nunique_blog_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b8cee9-caca-43a4-a0b2-7356de17e13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blog_12861    1253\n",
       "blog_8404     1120\n",
       "blog_3960     1108\n",
       "blog_9660      884\n",
       "blog_17014     847\n",
       "              ... \n",
       "blog_14983       2\n",
       "blog_7449        2\n",
       "blog_3639        2\n",
       "blog_7450        2\n",
       "blog_17707       2\n",
       "Name: id, Length: 19192, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nunique_blog_data.id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab6b512d-81ab-4f6f-8c7e-e1d8f7ac16e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345171, 36135)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nunique_blog_data.to_csv(FILE_PATH+\"blog_as_csv_preprocessed.csv\", index=False)\n",
    "# blog_data = pd.read_csv(FILE_PATH+\"blog_as_csv_preprocessed.csv\")\n",
    "blog_train, blog_test = train_test_split_by_author(nunique_blog_data)\n",
    "blog_train.to_csv(FILE_PATH+\"blog_train.csv\", index=False)\n",
    "blog_test.to_csv(FILE_PATH+\"blog_test.csv\", index=False)\n",
    "len(blog_train), len(blog_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e51f9a-1c45-42d7-853d-71e055d59288",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Mail\n",
    "https://www.kaggle.com/datasets/wcukierski/enron-email-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f66053-91ed-49f7-8aaa-b24ff0a47f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file                                            message\n",
       "0   allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1  allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df = pd.read_csv(FILE_PATH+\"enron-emails.csv\")\n",
    "emails_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe5d3414-68ef-45e0-8f96-e494bbbee097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(tim.belden@enron.com)</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        From                         To  \\\n",
       "0  (phillip.allen@enron.com)     (tim.belden@enron.com)   \n",
       "1  (phillip.allen@enron.com)  (john.lavorato@enron.com)   \n",
       "\n",
       "                                                Text  \\\n",
       "0                          Here is our forecast\\n\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "\n",
       "                                    Date  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)   \n",
       "\n",
       "                                             message  \n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...  \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import email\n",
    "def get_text_from_email(msg):\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append(part.get_payload())\n",
    "    return ''.join(parts)\n",
    "\n",
    "\n",
    "def split_email_addresses(line):\n",
    "    '''To separate multiple email addresses'''\n",
    "    if line:\n",
    "        addrs = line.split(',')\n",
    "        addrs = frozenset(map(lambda x: x.strip(), addrs))\n",
    "    else:\n",
    "        addrs = None\n",
    "    return addrs\n",
    "\n",
    "\n",
    "# Parse the emails into a list email objects\n",
    "messages = list(map(email.message_from_string, emails_df['message'])) \n",
    "for key in messages[0].keys():\n",
    "    emails_df[key] = [doc[key] for doc in messages]\n",
    "emails_df['Text'] = list(map(get_text_from_email, messages))\n",
    "emails_df['From'] = emails_df['From'].map(split_email_addresses)\n",
    "emails_df['To'] = emails_df['To'].map(split_email_addresses)\n",
    "del messages\n",
    "emails_df = emails_df[['From', 'To', 'Text', 'Date', 'message']]\n",
    "emails_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c3202ed-c54c-4eea-82b8-ddb0ae5a61a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(tim.belden@enron.com)</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      From                         To  \\\n",
       "0  phillip.allen@enron.com     (tim.belden@enron.com)   \n",
       "1  phillip.allen@enron.com  (john.lavorato@enron.com)   \n",
       "\n",
       "                                                Text  \\\n",
       "0                          Here is our forecast\\n\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "\n",
       "                                    Date  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)   \n",
       "\n",
       "                                             message  \n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...  \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in emails_df.index:\n",
    "    sender = emails_df.loc[i, 'From']\n",
    "    receiver = emails_df.loc[i, 'To']\n",
    "    if type(sender) is list and len(sender) > 1:\n",
    "        print('More than 1 sender:', sender)\n",
    "    \n",
    "    # if receiver is None:\n",
    "    #     receiver = 'nan'\n",
    "    # # elif len(emails_df.loc[i, 'To']) > 1:\n",
    "    # #     print('More than 1 receiver:', emails_df.loc[i, 'To'])\n",
    "    \n",
    "emails_df['From'] = emails_df[\"From\"].apply(lambda x: list(x)[0])\n",
    "# emails_df['To'] = emails_df[\"To\"].apply(lambda x: ' '.join(list(x)))#.astype(\"unicode\")\n",
    "emails_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "372150b3-2799-466c-86c2-656dd7d545f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>362497</th>\n",
       "      <td>debra.perlingiere@enron.com</td>\n",
       "      <td>(veronica.espinoza@enron.com)</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>Thu, 20 Jul 2000 06:57:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;29042400.1075842319607.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359528</th>\n",
       "      <td>debra.perlingiere@enron.com</td>\n",
       "      <td>(veronica.espinoza@enron.com)</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>Thu, 20 Jul 2000 06:57:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;21091781.1075842295609.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254750</th>\n",
       "      <td>news@real-net.net</td>\n",
       "      <td>(pkeavey@ect.enron.com)</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t[IMAGE]\\n\\t\\t\\t\\t\\t\\t\\t\\t\\...</td>\n",
       "      <td>Tue, 28 Nov 2000 08:52:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;10664196.1075855642165.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253583</th>\n",
       "      <td>news@real-net.net</td>\n",
       "      <td>(pkeavey@ect.enron.com)</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t[IMAGE]\\n\\t\\t\\t\\t\\t\\t\\t\\t\\...</td>\n",
       "      <td>Tue, 28 Nov 2000 08:52:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;5846818.1075855635419.JavaMail.ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253196</th>\n",
       "      <td>news@real-net.net</td>\n",
       "      <td>(pkeavey@ect.enron.com)</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t[IMAGE]\\n\\t\\t\\t\\t\\t\\t\\t\\t\\...</td>\n",
       "      <td>Tue, 28 Nov 2000 08:52:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;13427260.1075855626376.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12515</th>\n",
       "      <td>bushnews@georgewbush.com</td>\n",
       "      <td>(ebass@enron.com)</td>\n",
       "      <td>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...</td>\n",
       "      <td>Sat, 2 Dec 2000 21:10:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;16755277.1075854579182.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13871</th>\n",
       "      <td>bushnews@georgewbush.com</td>\n",
       "      <td>(ebass@enron.com)</td>\n",
       "      <td>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...</td>\n",
       "      <td>Sat, 2 Dec 2000 21:10:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;13935886.1075854652367.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12612</th>\n",
       "      <td>bushnews@georgewbush.com</td>\n",
       "      <td>(ebass@enron.com)</td>\n",
       "      <td>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...</td>\n",
       "      <td>Tue, 28 Nov 2000 17:48:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;19045496.1075854582239.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15164</th>\n",
       "      <td>bushnews@georgewbush.com</td>\n",
       "      <td>(ebass@enron.com)</td>\n",
       "      <td>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...</td>\n",
       "      <td>Tue, 28 Nov 2000 17:48:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;15114726.1075854649305.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15686</th>\n",
       "      <td>bushnews@georgewbush.com</td>\n",
       "      <td>(ebass@enron.com)</td>\n",
       "      <td>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...</td>\n",
       "      <td>Tue, 28 Nov 2000 17:48:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;17681416.1075854670427.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392765 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               From                             To  \\\n",
       "362497  debra.perlingiere@enron.com  (veronica.espinoza@enron.com)   \n",
       "359528  debra.perlingiere@enron.com  (veronica.espinoza@enron.com)   \n",
       "254750            news@real-net.net        (pkeavey@ect.enron.com)   \n",
       "253583            news@real-net.net        (pkeavey@ect.enron.com)   \n",
       "253196            news@real-net.net        (pkeavey@ect.enron.com)   \n",
       "...                             ...                            ...   \n",
       "12515      bushnews@georgewbush.com              (ebass@enron.com)   \n",
       "13871      bushnews@georgewbush.com              (ebass@enron.com)   \n",
       "12612      bushnews@georgewbush.com              (ebass@enron.com)   \n",
       "15164      bushnews@georgewbush.com              (ebass@enron.com)   \n",
       "15686      bushnews@georgewbush.com              (ebass@enron.com)   \n",
       "\n",
       "                                                     Text  \\\n",
       "362497  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...   \n",
       "359528  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...   \n",
       "254750  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t[IMAGE]\\n\\t\\t\\t\\t\\t\\t\\t\\t\\...   \n",
       "253583  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t[IMAGE]\\n\\t\\t\\t\\t\\t\\t\\t\\t\\...   \n",
       "253196  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t[IMAGE]\\n\\t\\t\\t\\t\\t\\t\\t\\t\\...   \n",
       "...                                                   ...   \n",
       "12515   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...   \n",
       "13871   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...   \n",
       "12612   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...   \n",
       "15164   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...   \n",
       "15686   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...   \n",
       "\n",
       "                                         Date  \\\n",
       "362497  Thu, 20 Jul 2000 06:57:00 -0700 (PDT)   \n",
       "359528  Thu, 20 Jul 2000 06:57:00 -0700 (PDT)   \n",
       "254750  Tue, 28 Nov 2000 08:52:00 -0800 (PST)   \n",
       "253583  Tue, 28 Nov 2000 08:52:00 -0800 (PST)   \n",
       "253196  Tue, 28 Nov 2000 08:52:00 -0800 (PST)   \n",
       "...                                       ...   \n",
       "12515    Sat, 2 Dec 2000 21:10:00 -0800 (PST)   \n",
       "13871    Sat, 2 Dec 2000 21:10:00 -0800 (PST)   \n",
       "12612   Tue, 28 Nov 2000 17:48:00 -0800 (PST)   \n",
       "15164   Tue, 28 Nov 2000 17:48:00 -0800 (PST)   \n",
       "15686   Tue, 28 Nov 2000 17:48:00 -0800 (PST)   \n",
       "\n",
       "                                                  message  \n",
       "362497  Message-ID: <29042400.1075842319607.JavaMail.e...  \n",
       "359528  Message-ID: <21091781.1075842295609.JavaMail.e...  \n",
       "254750  Message-ID: <10664196.1075855642165.JavaMail.e...  \n",
       "253583  Message-ID: <5846818.1075855635419.JavaMail.ev...  \n",
       "253196  Message-ID: <13427260.1075855626376.JavaMail.e...  \n",
       "...                                                   ...  \n",
       "12515   Message-ID: <16755277.1075854579182.JavaMail.e...  \n",
       "13871   Message-ID: <13935886.1075854652367.JavaMail.e...  \n",
       "12612   Message-ID: <19045496.1075854582239.JavaMail.e...  \n",
       "15164   Message-ID: <15114726.1075854649305.JavaMail.e...  \n",
       "15686   Message-ID: <17681416.1075854670427.JavaMail.e...  \n",
       "\n",
       "[392765 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding and removing duplicate rows\n",
    "emails_df[emails_df[['From', 'To', 'Text', 'Date']].duplicated(keep=False)].sort_values('Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "118ba7f9-aef7-4f1b-b4e0-29c56d0dd7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255451, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df = emails_df.drop_duplicates(subset=['From', 'To', 'Text', 'Date'], keep='first').reset_index(drop=True)\n",
    "emails_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ebbc2ae-63ff-42b1-a0ab-bac5d64c2781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>receiver</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>message_old</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(tim.belden@enron.com)</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(leah.arsdall@enron.com)</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(randall.gay@enron.com)</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(greg.piper@enron.com)</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255446</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(kori.loibl@enron.com)</td>\n",
       "      <td>This is a trade with OIL-SPEC-HEDGE-NG (John L...</td>\n",
       "      <td>Wed, 28 Nov 2001 13:30:11 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;26807948.1075842029936.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255447</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Some of my position is with the Alberta Term b...</td>\n",
       "      <td>Wed, 28 Nov 2001 12:47:48 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;25835861.1075842029959.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255448</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(dawn.doucet@enron.com)</td>\n",
       "      <td>2\\n\\n -----Original Message-----\\nFrom: \\tDouc...</td>\n",
       "      <td>Wed, 28 Nov 2001 07:20:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;28979867.1075842029988.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255449</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(jeanie.slone@enron.com)</td>\n",
       "      <td>Analyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\t\\...</td>\n",
       "      <td>Tue, 27 Nov 2001 11:52:45 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;22052556.1075842030013.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255450</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(livia_zufferli@monitor.com)</td>\n",
       "      <td>i think the YMCA has a class that is for peopl...</td>\n",
       "      <td>Mon, 26 Nov 2001 10:48:43 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;28618979.1075842030037.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255451 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user                      receiver  \\\n",
       "0       phillip.allen@enron.com        (tim.belden@enron.com)   \n",
       "1       phillip.allen@enron.com     (john.lavorato@enron.com)   \n",
       "2       phillip.allen@enron.com      (leah.arsdall@enron.com)   \n",
       "3       phillip.allen@enron.com       (randall.gay@enron.com)   \n",
       "4       phillip.allen@enron.com        (greg.piper@enron.com)   \n",
       "...                         ...                           ...   \n",
       "255446  john.zufferli@enron.com        (kori.loibl@enron.com)   \n",
       "255447  john.zufferli@enron.com     (john.lavorato@enron.com)   \n",
       "255448  john.zufferli@enron.com       (dawn.doucet@enron.com)   \n",
       "255449  john.zufferli@enron.com      (jeanie.slone@enron.com)   \n",
       "255450  john.zufferli@enron.com  (livia_zufferli@monitor.com)   \n",
       "\n",
       "                                                     text  \\\n",
       "0                               Here is our forecast\\n\\n    \n",
       "1       Traveling to have a business meeting takes the...   \n",
       "2                          test successful.  way to go!!!   \n",
       "3       Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                     Let's shoot for Tuesday at 11:45.     \n",
       "...                                                   ...   \n",
       "255446  This is a trade with OIL-SPEC-HEDGE-NG (John L...   \n",
       "255447  Some of my position is with the Alberta Term b...   \n",
       "255448  2\\n\\n -----Original Message-----\\nFrom: \\tDouc...   \n",
       "255449  Analyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\t\\...   \n",
       "255450  i think the YMCA has a class that is for peopl...   \n",
       "\n",
       "                                         date  \\\n",
       "0       Mon, 14 May 2001 16:39:00 -0700 (PDT)   \n",
       "1        Fri, 4 May 2001 13:51:00 -0700 (PDT)   \n",
       "2       Wed, 18 Oct 2000 03:00:00 -0700 (PDT)   \n",
       "3       Mon, 23 Oct 2000 06:13:00 -0700 (PDT)   \n",
       "4       Thu, 31 Aug 2000 05:07:00 -0700 (PDT)   \n",
       "...                                       ...   \n",
       "255446  Wed, 28 Nov 2001 13:30:11 -0800 (PST)   \n",
       "255447  Wed, 28 Nov 2001 12:47:48 -0800 (PST)   \n",
       "255448  Wed, 28 Nov 2001 07:20:00 -0800 (PST)   \n",
       "255449  Tue, 27 Nov 2001 11:52:45 -0800 (PST)   \n",
       "255450  Mon, 26 Nov 2001 10:48:43 -0800 (PST)   \n",
       "\n",
       "                                              message_old         id  \n",
       "0       Message-ID: <18782981.1075855378110.JavaMail.e...     mail_0  \n",
       "1       Message-ID: <15464986.1075855378456.JavaMail.e...     mail_0  \n",
       "2       Message-ID: <24216240.1075855687451.JavaMail.e...     mail_0  \n",
       "3       Message-ID: <13505866.1075863688222.JavaMail.e...     mail_0  \n",
       "4       Message-ID: <30922949.1075863688243.JavaMail.e...     mail_0  \n",
       "...                                                   ...        ...  \n",
       "255446  Message-ID: <26807948.1075842029936.JavaMail.e...  mail_5460  \n",
       "255447  Message-ID: <25835861.1075842029959.JavaMail.e...  mail_5460  \n",
       "255448  Message-ID: <28979867.1075842029988.JavaMail.e...  mail_5460  \n",
       "255449  Message-ID: <22052556.1075842030013.JavaMail.e...  mail_5460  \n",
       "255450  Message-ID: <28618979.1075842030037.JavaMail.e...  mail_5460  \n",
       "\n",
       "[255451 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail_corpus = emails_df.copy()\n",
    "mail_corpus.columns = ['user', 'receiver', 'text', 'date', 'message_old']\n",
    "unique_author = mail_corpus['user'].unique()\n",
    "email_mapping = {k: v for k, v in zip(unique_author, range(len(unique_author)))}\n",
    "mail_corpus['id'] = mail_corpus['user'].apply(lambda x: 'mail_'+str(email_mapping[x]))\n",
    "mail_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "442ec3a9-0007-4b17-b9be-d6f527bf92b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>receiver</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>message_old</th>\n",
       "      <th>id</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(tim.belden@enron.com)</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "      <td>\\nTraveling to have a business meeting takes t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(leah.arsdall@enron.com)</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(randall.gay@enron.com)</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "      <td>\\nRandy,\\n\\n Can you send me a schedule of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>(greg.piper@enron.com)</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>mail_0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255446</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(kori.loibl@enron.com)</td>\n",
       "      <td>This is a trade with OIL-SPEC-HEDGE-NG (John L...</td>\n",
       "      <td>Wed, 28 Nov 2001 13:30:11 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;26807948.1075842029936.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "      <td>\\nThis is a trade with OIL-SPEC-HEDGE-NG (John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255447</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Some of my position is with the Alberta Term b...</td>\n",
       "      <td>Wed, 28 Nov 2001 12:47:48 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;25835861.1075842029959.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255448</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(dawn.doucet@enron.com)</td>\n",
       "      <td>2\\n\\n -----Original Message-----\\nFrom: \\tDouc...</td>\n",
       "      <td>Wed, 28 Nov 2001 07:20:00 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;28979867.1075842029988.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "      <td>\\n2\\n\\n -----Original Message-----\\nSent:\\tWed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255449</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(jeanie.slone@enron.com)</td>\n",
       "      <td>Analyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\t\\...</td>\n",
       "      <td>Tue, 27 Nov 2001 11:52:45 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;22052556.1075842030013.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "      <td>\\nAnalyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255450</th>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>(livia_zufferli@monitor.com)</td>\n",
       "      <td>i think the YMCA has a class that is for peopl...</td>\n",
       "      <td>Mon, 26 Nov 2001 10:48:43 -0800 (PST)</td>\n",
       "      <td>Message-ID: &lt;28618979.1075842030037.JavaMail.e...</td>\n",
       "      <td>mail_5460</td>\n",
       "      <td>\\ni think the YMCA has a class that is for peo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255451 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user                      receiver  \\\n",
       "0       phillip.allen@enron.com        (tim.belden@enron.com)   \n",
       "1       phillip.allen@enron.com     (john.lavorato@enron.com)   \n",
       "2       phillip.allen@enron.com      (leah.arsdall@enron.com)   \n",
       "3       phillip.allen@enron.com       (randall.gay@enron.com)   \n",
       "4       phillip.allen@enron.com        (greg.piper@enron.com)   \n",
       "...                         ...                           ...   \n",
       "255446  john.zufferli@enron.com        (kori.loibl@enron.com)   \n",
       "255447  john.zufferli@enron.com     (john.lavorato@enron.com)   \n",
       "255448  john.zufferli@enron.com       (dawn.doucet@enron.com)   \n",
       "255449  john.zufferli@enron.com      (jeanie.slone@enron.com)   \n",
       "255450  john.zufferli@enron.com  (livia_zufferli@monitor.com)   \n",
       "\n",
       "                                                     text  \\\n",
       "0                               Here is our forecast\\n\\n    \n",
       "1       Traveling to have a business meeting takes the...   \n",
       "2                          test successful.  way to go!!!   \n",
       "3       Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                     Let's shoot for Tuesday at 11:45.     \n",
       "...                                                   ...   \n",
       "255446  This is a trade with OIL-SPEC-HEDGE-NG (John L...   \n",
       "255447  Some of my position is with the Alberta Term b...   \n",
       "255448  2\\n\\n -----Original Message-----\\nFrom: \\tDouc...   \n",
       "255449  Analyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\t\\...   \n",
       "255450  i think the YMCA has a class that is for peopl...   \n",
       "\n",
       "                                         date  \\\n",
       "0       Mon, 14 May 2001 16:39:00 -0700 (PDT)   \n",
       "1        Fri, 4 May 2001 13:51:00 -0700 (PDT)   \n",
       "2       Wed, 18 Oct 2000 03:00:00 -0700 (PDT)   \n",
       "3       Mon, 23 Oct 2000 06:13:00 -0700 (PDT)   \n",
       "4       Thu, 31 Aug 2000 05:07:00 -0700 (PDT)   \n",
       "...                                       ...   \n",
       "255446  Wed, 28 Nov 2001 13:30:11 -0800 (PST)   \n",
       "255447  Wed, 28 Nov 2001 12:47:48 -0800 (PST)   \n",
       "255448  Wed, 28 Nov 2001 07:20:00 -0800 (PST)   \n",
       "255449  Tue, 27 Nov 2001 11:52:45 -0800 (PST)   \n",
       "255450  Mon, 26 Nov 2001 10:48:43 -0800 (PST)   \n",
       "\n",
       "                                              message_old         id  \\\n",
       "0       Message-ID: <18782981.1075855378110.JavaMail.e...     mail_0   \n",
       "1       Message-ID: <15464986.1075855378456.JavaMail.e...     mail_0   \n",
       "2       Message-ID: <24216240.1075855687451.JavaMail.e...     mail_0   \n",
       "3       Message-ID: <13505866.1075863688222.JavaMail.e...     mail_0   \n",
       "4       Message-ID: <30922949.1075863688243.JavaMail.e...     mail_0   \n",
       "...                                                   ...        ...   \n",
       "255446  Message-ID: <26807948.1075842029936.JavaMail.e...  mail_5460   \n",
       "255447  Message-ID: <25835861.1075842029959.JavaMail.e...  mail_5460   \n",
       "255448  Message-ID: <28979867.1075842029988.JavaMail.e...  mail_5460   \n",
       "255449  Message-ID: <22052556.1075842030013.JavaMail.e...  mail_5460   \n",
       "255450  Message-ID: <28618979.1075842030037.JavaMail.e...  mail_5460   \n",
       "\n",
       "                                               clean_text  \n",
       "0                                                          \n",
       "1       \\nTraveling to have a business meeting takes t...  \n",
       "2                                                          \n",
       "3       \\nRandy,\\n\\n Can you send me a schedule of the...  \n",
       "4                                                          \n",
       "...                                                   ...  \n",
       "255446  \\nThis is a trade with OIL-SPEC-HEDGE-NG (John...  \n",
       "255447                                                     \n",
       "255448  \\n2\\n\\n -----Original Message-----\\nSent:\\tWed...  \n",
       "255449  \\nAnalyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\...  \n",
       "255450  \\ni think the YMCA has a class that is for peo...  \n",
       "\n",
       "[255451 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    clean_mail = re.sub(r'(\\\\+r)?(\\\\+n)+', '\\n', text)\n",
    "    clean_mail = re.sub(r'\\\\+t', '\\t', clean_mail)\n",
    "    clean_mail = '\\n'.join(clean_mail.strip().split('\\n')[15:-1])\n",
    "    clean_mail = re.sub(r'X-.+:.*\\n', '<s>', clean_mail)\n",
    "    clean_mail = re.sub(r'From:.*\\n', '', clean_mail)\n",
    "    clean_mail = re.sub(r\"\\\\'\", \"'\", clean_mail)\n",
    "    return clean_mail\n",
    "\n",
    "mail_corpus['clean_text'] = mail_corpus['message_old'].apply(clean_text)\n",
    "mail_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f7a0c7-25d9-426b-8996-9fc209f72c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail_corpus.clean_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eef4f2cd-9d25-4b91-a1a9-dce92e75134b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e53e3472e8346b3b121de6a0f16822d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2133 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2109 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (19075 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (34924 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (164282 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mail_10002</td>\n",
       "      <td>[0, 1185, 9918, 12180, 13, 10, 2041, 8, 6449, ...</td>\n",
       "      <td>&lt;s&gt;You Could Search for a Year and Find Nothin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mail_10002</td>\n",
       "      <td>[50140, 50118, 50118, 2709, 901, 3522, 2578, 4...</td>\n",
       "      <td>\\n\\n\\n\\nFor More Information Click Below Now\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mail_10000</td>\n",
       "      <td>[0, 4014, 13181, 104, 10616, 20685, 7224, 500,...</td>\n",
       "      <td>&lt;s&gt;STOCKS ARE DOWN ACROSS THE BOARD\\n         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mail_10000</td>\n",
       "      <td>[5298, 7, 1437, 50118, 34335, 6, 51, 10557, 7,...</td>\n",
       "      <td>symptoms to \\ndevelop, they intend to diagnos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mail_10009</td>\n",
       "      <td>[0, 3293, 347, 491, 14718, 29, 108, 1426, 155,...</td>\n",
       "      <td>&lt;s&gt;OTC News Alerts' Last 3 Picks have gained 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299088</th>\n",
       "      <td>mail_9524</td>\n",
       "      <td>[1232, 31, 2086, 960, 6, 16, 7, 489, 7458, 521...</td>\n",
       "      <td>families from losing everything, is to keep m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299089</th>\n",
       "      <td>mail_9524</td>\n",
       "      <td>[10, 948, 9, 688, 6, 229, 15964, 34, 1224, 31,...</td>\n",
       "      <td>a matter of weeks, Kmart has turned from a po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299090</th>\n",
       "      <td>mail_9524</td>\n",
       "      <td>[5214, 50118, 29, 7834, 6, 3854, 8, 647, 1743,...</td>\n",
       "      <td>=\\ns inventory, distribution and sales systems...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299091</th>\n",
       "      <td>mail_9524</td>\n",
       "      <td>[13147, 4, 5457, 3546, 50118, 50118, 15075, 11...</td>\n",
       "      <td>Reserved. =09\\n\\nCity - City Diary - Enron go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299092</th>\n",
       "      <td>mail_9524</td>\n",
       "      <td>[14, 18, 15, 961, 18, 1508, 6, 5, 388, 425, 4,...</td>\n",
       "      <td>that's on everyone's mind, the stock price.  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                  pretokenized_text  \\\n",
       "0       mail_10002  [0, 1185, 9918, 12180, 13, 10, 2041, 8, 6449, ...   \n",
       "1       mail_10002  [50140, 50118, 50118, 2709, 901, 3522, 2578, 4...   \n",
       "2       mail_10000  [0, 4014, 13181, 104, 10616, 20685, 7224, 500,...   \n",
       "3       mail_10000  [5298, 7, 1437, 50118, 34335, 6, 51, 10557, 7,...   \n",
       "4       mail_10009  [0, 3293, 347, 491, 14718, 29, 108, 1426, 155,...   \n",
       "...            ...                                                ...   \n",
       "299088   mail_9524  [1232, 31, 2086, 960, 6, 16, 7, 489, 7458, 521...   \n",
       "299089   mail_9524  [10, 948, 9, 688, 6, 229, 15964, 34, 1224, 31,...   \n",
       "299090   mail_9524  [5214, 50118, 29, 7834, 6, 3854, 8, 647, 1743,...   \n",
       "299091   mail_9524  [13147, 4, 5457, 3546, 50118, 50118, 15075, 11...   \n",
       "299092   mail_9524  [14, 18, 15, 961, 18, 1508, 6, 5, 388, 425, 4,...   \n",
       "\n",
       "                                             decoded_text  \n",
       "0       <s>You Could Search for a Year and Find Nothin...  \n",
       "1       \\n\\n\\n\\nFor More Information Click Below Now\\n...  \n",
       "2       <s>STOCKS ARE DOWN ACROSS THE BOARD\\n         ...  \n",
       "3        symptoms to \\ndevelop, they intend to diagnos...  \n",
       "4       <s>OTC News Alerts' Last 3 Picks have gained 3...  \n",
       "...                                                   ...  \n",
       "299088   families from losing everything, is to keep m...  \n",
       "299089   a matter of weeks, Kmart has turned from a po...  \n",
       "299090  =\\ns inventory, distribution and sales systems...  \n",
       "299091   Reserved. =09\\n\\nCity - City Diary - Enron go...  \n",
       "299092   that's on everyone's mind, the stock price.  ...  \n",
       "\n",
       "[299093 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mail_corpus.columns = ['user', 'old_text', 'id', 'text']\n",
    "mail_corpus.text = mail_corpus.text.apply(lambda x: x.strip())\n",
    "clean_mail_corpus = mail_corpus[['id', 'text']].groupby(\"id\").agg(lambda x: '<\\s>'.join(x))\n",
    "\n",
    "chunked_mail_data = build_chunk_dataframe(clean_mail_corpus, None)\n",
    "nunique_mail_data = clean_non_unique(chunked_mail_data)\n",
    "nunique_mail_data.reset_index(drop=True, inplace=True)\n",
    "nunique_mail_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b88cd3d-ca68-4030-b655-83064838c47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276158, 22935)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nunique_mail_data.to_csv(FILE_PATH+\"mail_as_csv_preprocessed.csv\", index=False)\n",
    "mail_train, mail_test = train_test_split_by_author(nunique_mail_data)\n",
    "mail_train.to_csv(FILE_PATH+\"mail_train.csv\", index=False)\n",
    "mail_test.to_csv(FILE_PATH+\"mail_test.csv\", index=False)\n",
    "len(mail_train), len(mail_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "066ac736-99ac-45e7-a802-614199919250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    \\n\\n\\n\\nFor More Information Click Below Now\\n...\n",
       "1     symptoms to \\ndevelop, they intend to diagnos...\n",
       "1     Application to Catastrophe Insurance\\nhttp://...\n",
       "1     to the accuracy or the\\ncompleteness of the d...\n",
       "1    cocktails.\\n\\nJeff<\\s>Yes, put 20 on black if ...\n",
       "                           ...                        \n",
       "1     Volatility Matrix      (Click on imag=\\ne to ...\n",
       "1    ty, Robert; Allwein, Robert; Goodell, Scott; O...\n",
       "1     **\\n-Upgrade information\\n-Important updates\\...\n",
       "1     LET UTILITIES OUT OF CALPX\\nThe California Pu...\n",
       "1     were answered in full during the meeting.  I ...\n",
       "Name: decoded_text, Length: 11100, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nunique_mail_data.decoded_text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b2742-22ae-434d-970b-0d2a594df0ed",
   "metadata": {},
   "source": [
    "## Reddit\n",
    "\n",
    "https://github.com/LLNL/LUAR/blob/main/scripts/download_reddit_data.sh\n",
    "\n",
    "data.jsonl (62G) download https://storage.googleapis.com/naacl21_account_linking/raw_mud.tar.gz\n",
    "\n",
    "300 million Reddit posts from 1 million users published over an entire year to be used to train our proposed model.\n",
    "This Million User Dataset (MUD) consists of all posts by authors who published at least 100 and at most 1000 posts between July 2015 and June 2016, where the lower bound ensures a sufficiently long history from which to sample, and the upper bound is intended to reduce the impact of bot and spam account. Together with its text content, each comment is labeled by its publication time and the subreddit to which it was posted, a categorical feature roughly indicating its topic.\n",
    "\n",
    "Data source: Khan, Aleem, et al. \"A deep metric learning approach to account linking.\" NAACL (2021). https://arxiv.org/pdf/2105.07263.pdf\n",
    "The data by are drawed from the existing Pushshift Reddit corpus (Baumgartner, Jason, et al. \"The pushshift reddit dataset.\" AAAI. Vol. 14. 2020. https://arxiv.org/pdf/2001.08435.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c20638-6601-4a63-b4a5-b3df6d76be85",
   "metadata": {},
   "source": [
    "| Number of users contributing                       | 1,071,477   |\n",
    "|----------------------------------------------------|-------------|\n",
    "| Number of posts                                    | 321,659,421 |\n",
    "| Mean post length                                   | 42.5 tokens |\n",
    "| Mean number of posts contributed by a user         | 300.2       |\n",
    "| Mean number of subreddits accessed by a user       | 22.1        |\n",
    "| Mean number of months a user was active            | 9.9         |\n",
    "| Percentage of posts containing more than 64 tokens | 17.37%      | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4ae2f9-e3a4-47d2-a36b-917678f3c864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,071,477\n",
      "CPU times: user 6min 29s, sys: 2min 19s, total: 8min 49s\n",
      "Wall time: 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data.jsonl (62G) download https://storage.googleapis.com/naacl21_account_linking/raw_mud.tar.gz\n",
    "df = pd.read_json(FILE_PATH+'reddit_mud/data.jsonl', lines=True)\n",
    "print(f\"{df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c676495d-f0cc-4c5b-936c-f13b07192d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321,659,421\n",
      "CPU times: user 54.8 s, sys: 12.6 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df[['syms', 'author_id', 'action_type']]\n",
    "df.rename(columns={'syms': 'text', 'author_id': 'id', 'action_type': 'topic'}, inplace=True)\n",
    "df = df.explode(['text', 'topic'], ignore_index=True)\n",
    "print(f\"{df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd38779-4180-43bf-9232-056b8d1d5f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicates: 23,811,501 sanity check: 23,811,501\n",
      "Before removing duplicates, # rows: 321,659,421\n",
      "New # rows:: 318,647,132\n",
      "CPU times: user 16min 56s, sys: 3min 8s, total: 20min 5s\n",
      "Wall time: 20min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('# duplicates:', f\"{df.text.duplicated().sum():,}\", 'sanity check:', f\"{df.shape[0] - len(set(df.text)):,}\")\n",
    "print('Before removing duplicates, # rows:', f\"{df.shape[0]:,}\")\n",
    "df = df.drop_duplicates(subset=['id', 'text', 'topic'], keep='first').reset_index(drop=True)\n",
    "print('New # rows::', f\"{df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba1ed81-42f9-408f-81c4-9cce3b508aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows with empty text: 5285\n",
      "318,641,847\n",
      "CPU times: user 59 s, sys: 12.4 s, total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('# rows with empty text:', (df['text'].values == '').sum())\n",
    "df = df[df['text'] != '']\n",
    "print(f\"{df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8153060a-dba7-4619-b437-2dc0032496ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I dash attack waaaayyyyy too often</td>\n",
       "      <td>reddit_0</td>\n",
       "      <td>smashbros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SO HAPPY ARMADA CAME THROUGH AGAINST THE PUNK ...</td>\n",
       "      <td>reddit_0</td>\n",
       "      <td>smashbros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anyone have a replay of this? I missed it</td>\n",
       "      <td>reddit_0</td>\n",
       "      <td>smashbros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You look like a dead goldfish that was left in...</td>\n",
       "      <td>reddit_0</td>\n",
       "      <td>RoastMe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poké Floats was legal??? Better not tell twitc...</td>\n",
       "      <td>reddit_0</td>\n",
       "      <td>smashbros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318647127</th>\n",
       "      <td>&amp;gt; campest dab</td>\n",
       "      <td>reddit_1071475</td>\n",
       "      <td>gifs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318647128</th>\n",
       "      <td>50m + whatever it cost to bribe the judge</td>\n",
       "      <td>reddit_1071475</td>\n",
       "      <td>todayilearned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318647129</th>\n",
       "      <td>Too late, the deed is done</td>\n",
       "      <td>reddit_1071475</td>\n",
       "      <td>gifs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318647130</th>\n",
       "      <td>teehee, the wedding will be fabulous either way</td>\n",
       "      <td>reddit_1071475</td>\n",
       "      <td>todayilearned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318647131</th>\n",
       "      <td>It would probably look something similar to th...</td>\n",
       "      <td>reddit_1071475</td>\n",
       "      <td>Overwatch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318641847 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text              id  \\\n",
       "0                         I dash attack waaaayyyyy too often        reddit_0   \n",
       "1          SO HAPPY ARMADA CAME THROUGH AGAINST THE PUNK ...        reddit_0   \n",
       "2                  Anyone have a replay of this? I missed it        reddit_0   \n",
       "3          You look like a dead goldfish that was left in...        reddit_0   \n",
       "4          Poké Floats was legal??? Better not tell twitc...        reddit_0   \n",
       "...                                                      ...             ...   \n",
       "318647127                                   &gt; campest dab  reddit_1071475   \n",
       "318647128          50m + whatever it cost to bribe the judge  reddit_1071475   \n",
       "318647129                         Too late, the deed is done  reddit_1071475   \n",
       "318647130   teehee, the wedding will be fabulous either way   reddit_1071475   \n",
       "318647131  It would probably look something similar to th...  reddit_1071475   \n",
       "\n",
       "                   topic  \n",
       "0              smashbros  \n",
       "1              smashbros  \n",
       "2              smashbros  \n",
       "3                RoastMe  \n",
       "4              smashbros  \n",
       "...                  ...  \n",
       "318647127           gifs  \n",
       "318647128  todayilearned  \n",
       "318647129           gifs  \n",
       "318647130  todayilearned  \n",
       "318647131      Overwatch  \n",
       "\n",
       "[318641847 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_mapping = {k: v for k, v in zip(df.id.unique(), range(len(df.id.unique())))}\n",
    "df['id'] = df['id'].apply(lambda x: 'reddit_' + str(author_mapping[x]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fe4a671-173d-4538-99f8-d67b4146ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 28s, sys: 1min 15s, total: 5min 44s\n",
      "Wall time: 5min 43s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reddit_0</th>\n",
       "      <td>[smashbros, smashbros, smashbros, RoastMe, sma...</td>\n",
       "      <td>I dash attack waaaayyyyy too often&lt;\\s&gt;SO HAPPY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_1</th>\n",
       "      <td>[DCcomics, totalwar, totalwar, totalwar, total...</td>\n",
       "      <td>Awesome, I'll be sure to check them out, thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_10</th>\n",
       "      <td>[baseball, politics, politics, printSF, printS...</td>\n",
       "      <td>Back in Texas.  Buddy had a kid in an up and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_100</th>\n",
       "      <td>[StreetFighter, StreetFighter, StreetFighter, ...</td>\n",
       "      <td>That's an old term.&lt;\\s&gt;I'm also somewhat new a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_1000</th>\n",
       "      <td>[relationships, relationships, relationships, ...</td>\n",
       "      <td>I'm so sorry your friend died. As for this sit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_999995</th>\n",
       "      <td>[roblox, roblox, roblox, roblox, roblox, roblo...</td>\n",
       "      <td>Lmfaoooo&lt;\\s&gt;The Fedora Tipping is actually an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_999996</th>\n",
       "      <td>[relationships, relationships, relationships, ...</td>\n",
       "      <td>I do this too. I tell ten unrelated stories in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_999997</th>\n",
       "      <td>[FantasyWarTactics, FantasyWarTactics, Fantasy...</td>\n",
       "      <td>Thats oddd i tested with my Dominique second s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_999998</th>\n",
       "      <td>[AskReddit, Fitness, Fitness, AskReddit, AskRe...</td>\n",
       "      <td>Painful, very drawn out, but final breakup wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_999999</th>\n",
       "      <td>[comicbooks, comicbooks, AskReddit, comicbooks...</td>\n",
       "      <td>(Wow, this is a seriously late reply and ended...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           topic  \\\n",
       "id                                                                 \n",
       "reddit_0       [smashbros, smashbros, smashbros, RoastMe, sma...   \n",
       "reddit_1       [DCcomics, totalwar, totalwar, totalwar, total...   \n",
       "reddit_10      [baseball, politics, politics, printSF, printS...   \n",
       "reddit_100     [StreetFighter, StreetFighter, StreetFighter, ...   \n",
       "reddit_1000    [relationships, relationships, relationships, ...   \n",
       "...                                                          ...   \n",
       "reddit_999995  [roblox, roblox, roblox, roblox, roblox, roblo...   \n",
       "reddit_999996  [relationships, relationships, relationships, ...   \n",
       "reddit_999997  [FantasyWarTactics, FantasyWarTactics, Fantasy...   \n",
       "reddit_999998  [AskReddit, Fitness, Fitness, AskReddit, AskRe...   \n",
       "reddit_999999  [comicbooks, comicbooks, AskReddit, comicbooks...   \n",
       "\n",
       "                                                            text  \n",
       "id                                                                \n",
       "reddit_0       I dash attack waaaayyyyy too often<\\s>SO HAPPY...  \n",
       "reddit_1       Awesome, I'll be sure to check them out, thank...  \n",
       "reddit_10      Back in Texas.  Buddy had a kid in an up and c...  \n",
       "reddit_100     That's an old term.<\\s>I'm also somewhat new a...  \n",
       "reddit_1000    I'm so sorry your friend died. As for this sit...  \n",
       "...                                                          ...  \n",
       "reddit_999995  Lmfaoooo<\\s>The Fedora Tipping is actually an ...  \n",
       "reddit_999996  I do this too. I tell ten unrelated stories in...  \n",
       "reddit_999997  Thats oddd i tested with my Dominique second s...  \n",
       "reddit_999998  Painful, very drawn out, but final breakup wit...  \n",
       "reddit_999999  (Wow, this is a seriously late reply and ended...  \n",
       "\n",
       "[1071476 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: x.strip())\n",
    "clean_reddit_corpus = df[['id', 'text']].groupby(\"id\").agg(lambda x: '<\\s>'.join(x))\n",
    "meta_reddit_corpus = df[['id', 'topic']].groupby(\"id\").agg(lambda x: [e for e in x])\n",
    "full_reddit_corpus = meta_reddit_corpus.merge(clean_reddit_corpus, on='id')\n",
    "full_reddit_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69750e86-b775-41cf-ac8e-1cd9c293ac7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d63a10f640472bb92813d2a62bedf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1071476 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2655 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3354 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7782 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6495 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7665 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4394 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9563 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (12215 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (39717 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (33282 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Time estimation: 3h 30min\n",
    "chunked_reddit_data = build_chunk_dataframe(full_reddit_corpus, meta_reddit_corpus)\n",
    "nunique_reddit_data = clean_non_unique(chunked_reddit_data)\n",
    "nunique_reddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d623e21-3988-4c92-b851-3871a6ad82a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reddit_1000000</td>\n",
       "      <td>[0, 8170, 71, 5, 7726, 3607, 5, 5466, 6, 89, 3...</td>\n",
       "      <td>&lt;s&gt;Even after the rocket leaves the atmosphere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reddit_1000000</td>\n",
       "      <td>[476, 804, 49069, 37457, 29, 15698, 10105, 70,...</td>\n",
       "      <td>power online.&lt;\\s&gt;Because all SPCs that end in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reddit_1000000</td>\n",
       "      <td>[5, 1272, 52, 33, 32, 31, 15503, 4458, 14, 126...</td>\n",
       "      <td>the problems we have are from furries that me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reddit_1000000</td>\n",
       "      <td>[18656, 49069, 37457, 29, 15698, 31593, 995, 2...</td>\n",
       "      <td>reens.&lt;\\s&gt;Fallout 4 will not full-screen for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reddit_1000000</td>\n",
       "      <td>[15698, 100, 16134, 3999, 1571, 5751, 4, 289, ...</td>\n",
       "      <td>&gt;Iddntity theft. Hacking of social media. Some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120872</th>\n",
       "      <td>reddit_999993</td>\n",
       "      <td>[49069, 37457, 29, 15698, 100, 524, 14, 621, 4...</td>\n",
       "      <td>.&lt;\\s&gt;I am that person. My parents influenced m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120873</th>\n",
       "      <td>reddit_999993</td>\n",
       "      <td>[611, 14118, 4, 1437, 50118, 50118, 100, 4157,...</td>\n",
       "      <td>chbag. \\n\\nI hate myself but at the very least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120874</th>\n",
       "      <td>reddit_999993</td>\n",
       "      <td>[21031, 10, 9310, 4, 50118, 50118, 40992, 110,...</td>\n",
       "      <td>Take a shower.\\n\\nCut your nails.\\n\\nDance to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120875</th>\n",
       "      <td>reddit_999993</td>\n",
       "      <td>[49069, 37457, 29, 15698, 11243, 16, 430, 6, 1...</td>\n",
       "      <td>.&lt;\\s&gt;Everyone is different,  no problem. \\n\\nM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120876</th>\n",
       "      <td>reddit_999993</td>\n",
       "      <td>[12443, 4, 1437, 50118, 50118, 133, 128, 2279,...</td>\n",
       "      <td>stranger. \\n\\nThe 'annoyance' or 'to an exten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30120438 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                  pretokenized_text  \\\n",
       "0         reddit_1000000  [0, 8170, 71, 5, 7726, 3607, 5, 5466, 6, 89, 3...   \n",
       "1         reddit_1000000  [476, 804, 49069, 37457, 29, 15698, 10105, 70,...   \n",
       "2         reddit_1000000  [5, 1272, 52, 33, 32, 31, 15503, 4458, 14, 126...   \n",
       "3         reddit_1000000  [18656, 49069, 37457, 29, 15698, 31593, 995, 2...   \n",
       "4         reddit_1000000  [15698, 100, 16134, 3999, 1571, 5751, 4, 289, ...   \n",
       "...                  ...                                                ...   \n",
       "30120872   reddit_999993  [49069, 37457, 29, 15698, 100, 524, 14, 621, 4...   \n",
       "30120873   reddit_999993  [611, 14118, 4, 1437, 50118, 50118, 100, 4157,...   \n",
       "30120874   reddit_999993  [21031, 10, 9310, 4, 50118, 50118, 40992, 110,...   \n",
       "30120875   reddit_999993  [49069, 37457, 29, 15698, 11243, 16, 430, 6, 1...   \n",
       "30120876   reddit_999993  [12443, 4, 1437, 50118, 50118, 133, 128, 2279,...   \n",
       "\n",
       "                                               decoded_text  \n",
       "0         <s>Even after the rocket leaves the atmosphere...  \n",
       "1          power online.<\\s>Because all SPCs that end in...  \n",
       "2          the problems we have are from furries that me...  \n",
       "3         reens.<\\s>Fallout 4 will not full-screen for m...  \n",
       "4         >Iddntity theft. Hacking of social media. Some...  \n",
       "...                                                     ...  \n",
       "30120872  .<\\s>I am that person. My parents influenced m...  \n",
       "30120873  chbag. \\n\\nI hate myself but at the very least...  \n",
       "30120874  Take a shower.\\n\\nCut your nails.\\n\\nDance to ...  \n",
       "30120875  .<\\s>Everyone is different,  no problem. \\n\\nM...  \n",
       "30120876   stranger. \\n\\nThe 'annoyance' or 'to an exten...  \n",
       "\n",
       "[30120438 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nunique_reddit_data[['id', 'pretokenized_text', 'decoded_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdca3621-6eed-46b8-a8c8-58e06bc7975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,071,476 30,120,877 30,120,438\n"
     ]
    }
   ],
   "source": [
    "print(f\"{full_reddit_corpus.shape[0]:,}\", f\"{chunked_reddit_data.shape[0]:,}\", f\"{nunique_reddit_data.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d32064de-c214-48ed-9fc4-d706282283d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/baixiang/dataset/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33307773-3732-473d-94f5-2532149547b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48min 4s, sys: 3min 52s, total: 51min 56s\n",
      "Wall time: 51min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nunique_reddit_data.reset_index(drop=True, inplace=True)\n",
    "nunique_reddit_data[['id', 'pretokenized_text', 'decoded_text']].to_csv(FILE_PATH+'reddit_mud/reddit_processed.csv', index=False)\n",
    "nunique_reddit_data[['id', 'decoded_text']].to_csv(FILE_PATH+'reddit_mud/reddit_pro_text_only.csv', index=False)  # smaller file size\n",
    "# df_reddit = pd.read_csv(FILE_PATH+\"reddit_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17b42938-23a2-4cc1-8fe8-95e40101af20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 29s, sys: 53.9 s, total: 12min 23s\n",
      "Wall time: 12min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reddit_train, reddit_test = train_test_split_by_author(nunique_reddit_data)\n",
    "reddit_train[['id', 'decoded_text']].to_csv(FILE_PATH+\"reddit_mud/reddit_train.csv\", index=False)\n",
    "reddit_test[['id', 'decoded_text']].to_csv(FILE_PATH+\"reddit_mud/reddit_test.csv\", index=False)\n",
    "# reddit_train[['id', 'pretokenized_text', 'decoded_text']].to_csv(FILE_PATH+\"reddit_mud/reddit_train_plus_token.csv\", index=False)\n",
    "# reddit_test[['id', 'pretokenized_text', 'decoded_text']].to_csv(FILE_PATH+\"reddit_mud/reddit_test_plus_token.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b388b4c-813e-4f8f-84fe-524faa928916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27,106,354 3,014,084\n"
     ]
    }
   ],
   "source": [
    "print(f\"{reddit_train.shape[0]:,}\", f\"{reddit_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34c35986-5c8c-461b-9af4-7a0b38557460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# reddit_train = pd.read_csv(FILE_PATH+\"reddit_mud/reddit_train.csv\")\n",
    "# reddit_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a7641d-372b-48f2-b8be-ff381f348bb5",
   "metadata": {},
   "source": [
    "### Topic (action_type) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "328dd73b-c30e-4a50-9f4e-7ca6c1aba9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "AskReddit          22892662\n",
       "leagueoflegends     5106245\n",
       "politics            3630520\n",
       "funny               3445469\n",
       "pics                3042891\n",
       "pcmasterrace        2948537\n",
       "worldnews           2915803\n",
       "videos              2902798\n",
       "GlobalOffensive     2718675\n",
       "nba                 2551179\n",
       "DotA2               2517609\n",
       "news                2515962\n",
       "todayilearned       2408060\n",
       "nfl                 2353151\n",
       "DestinyTheGame      2350909\n",
       "soccer              2345857\n",
       "gaming              2211573\n",
       "movies              2097312\n",
       "SquaredCircle       2093007\n",
       "The_Donald          1778814\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_cnt = df.topic.value_counts()\n",
    "val_cnt[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb7ab593-f576-4179-b1f7-394316b1aedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125186, 125186, 125186)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if letter case influences the number of topics\n",
    "len(val_cnt), len(np.unique(df.topic)), len(np.unique(df.topic.str.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844eecf3-7cf4-4905-8721-ad9985527745",
   "metadata": {},
   "source": [
    "### TODO: Language Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a606411d-e265-45c4-a62f-343e9a1fa4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[:1000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84404054-c4db-4675-aa63-cb81b75fea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en', 'fr')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langid\n",
    "langid.classify(\"War doesn't show who's right, just who's left.\")[0], langid.classify(\"C'est l'heure où les videurs deviennent gentils\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1d05f0b-2e6f-4a0e-839b-95a99d19b086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 766 ms, sys: 4.13 ms, total: 770 ms\n",
      "Wall time: 769 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(969, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df1['lang'] = df1['text'].apply(lambda x: langid.classify(x)[0])\n",
    "df1[df1['lang'] == 'en'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa3499-3c5f-4429-8953-623108131df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['lang'] = df['text'].apply(lambda x: langid.classify(x)[0])\n",
    "df[df['lang'] == 'en'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0744ff3-ad1e-45cf-8289-9cb1982434e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7dc8695-eee6-4d28-ac27-d98e63ad49bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "def get_english_word_rate(row):\n",
    "    row_words = row.text.lower().split() #decoded_text\n",
    "    word_count = len(row_words)\n",
    "    english_words = 0\n",
    "    for w in row_words:\n",
    "        if w in words.words():\n",
    "            english_words += 1\n",
    "    return english_words / word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89cdddb-63d3-41f9-be63-4d096bd875f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 23s, sys: 11.2 s, total: 17min 34s\n",
      "Wall time: 17min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(337, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# takes a long time to run\n",
    "df1['english_word_rate'] = df1.apply(get_english_word_rate, axis=1)\n",
    "df1[df1['english_word_rate'] > 0.75].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c23c6db1-5aec-4aa0-9b3a-c2c7fbbfc5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "      <th>english_word_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I dash attack waaaayyyyy too often</td>\n",
       "      <td>Sorry_I_Am_Canadian</td>\n",
       "      <td>smashbros</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SO HAPPY ARMADA CAME THROUGH AGAINST THE PUNK ...</td>\n",
       "      <td>Sorry_I_Am_Canadian</td>\n",
       "      <td>smashbros</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anyone have a replay of this? I missed it</td>\n",
       "      <td>Sorry_I_Am_Canadian</td>\n",
       "      <td>smashbros</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You look like a dead goldfish that was left in...</td>\n",
       "      <td>Sorry_I_Am_Canadian</td>\n",
       "      <td>RoastMe</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poké Floats was legal??? Better not tell twitc...</td>\n",
       "      <td>Sorry_I_Am_Canadian</td>\n",
       "      <td>smashbros</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Me too :( and I was really excited about this ...</td>\n",
       "      <td>goingHAMandcheese</td>\n",
       "      <td>GirlGamers</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Well, you're my hero.     \\nMany thanks!</td>\n",
       "      <td>goingHAMandcheese</td>\n",
       "      <td>GirlGamers</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Hope all is well now.</td>\n",
       "      <td>goingHAMandcheese</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>If you get a break, use it to take a walk inst...</td>\n",
       "      <td>goingHAMandcheese</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Exactly the same but with differently colored ...</td>\n",
       "      <td>goingHAMandcheese</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text                   id  \\\n",
       "0                   I dash attack waaaayyyyy too often  Sorry_I_Am_Canadian   \n",
       "1    SO HAPPY ARMADA CAME THROUGH AGAINST THE PUNK ...  Sorry_I_Am_Canadian   \n",
       "2            Anyone have a replay of this? I missed it  Sorry_I_Am_Canadian   \n",
       "3    You look like a dead goldfish that was left in...  Sorry_I_Am_Canadian   \n",
       "4    Poké Floats was legal??? Better not tell twitc...  Sorry_I_Am_Canadian   \n",
       "..                                                 ...                  ...   \n",
       "995  Me too :( and I was really excited about this ...    goingHAMandcheese   \n",
       "996          Well, you're my hero.     \\nMany thanks!     goingHAMandcheese   \n",
       "997                             Hope all is well now.     goingHAMandcheese   \n",
       "998  If you get a break, use it to take a walk inst...    goingHAMandcheese   \n",
       "999  Exactly the same but with differently colored ...    goingHAMandcheese   \n",
       "\n",
       "          topic  english_word_rate  \n",
       "0     smashbros           0.833333  \n",
       "1     smashbros           1.000000  \n",
       "2     smashbros           0.777778  \n",
       "3       RoastMe           0.950000  \n",
       "4     smashbros           0.666667  \n",
       "..          ...                ...  \n",
       "995  GirlGamers           0.850000  \n",
       "996  GirlGamers           0.333333  \n",
       "997   AskReddit           0.800000  \n",
       "998   AskReddit           0.782609  \n",
       "999   AskReddit           0.875000  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34814721-2660-42ee-86ee-4791627976e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4299ccbf-8421-4feb-9e2c-d7f19098f307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en', 'fr')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "detect(\"War doesn't show who's right, just who's left.\"), detect(\"C'est l'heure où les videurs deviennent gentils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a889b345-d4bd-4f05-bad4-1cf871df4bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LangDetectException",
     "evalue": "No features in text.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLangDetectException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/langdetect/detector_factory.py:130\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    128\u001b[0m detector \u001b[38;5;241m=\u001b[39m _factory\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m    129\u001b[0m detector\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/langdetect/detector.py:136\u001b[0m, in \u001b[0;36mDetector.detect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Detect language of the target text and return the language name\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    which has the highest probability.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m probabilities:\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlang\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/langdetect/detector.py:143\u001b[0m, in \u001b[0;36mDetector.get_probabilities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_probabilities\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_detect_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_probability(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob)\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/langdetect/detector.py:150\u001b[0m, in \u001b[0;36mDetector._detect_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m ngrams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_ngrams()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ngrams:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LangDetectException(ErrorCode\u001b[38;5;241m.\u001b[39mCantDetectError, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo features in text.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanglist)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n",
      "\u001b[0;31mLangDetectException\u001b[0m: No features in text."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df1['lang'] = df1['text'].apply(lambda x: detect(x))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e529ef-8ee0-41ad-bda8-84aae366bb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9fd4fe5-4f7d-414d-bbf2-f857aa55c027",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlid.176.ftz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mالشمس تشرق\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)) \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model('lid.176.ftz')\n",
    "print(model.predict('الشمس تشرق', k=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fa90fe-6e68-4925-af58-6a7142dec9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01eb5d33-e9a6-427d-a8bf-53e2052f0bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[0;32m----> 2\u001b[0m \u001b[43mTextBlob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWar doesn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt show who\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms right, sjust who\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms left.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_language\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/textblob/blob.py:597\u001b[0m, in \u001b[0;36mBaseBlob.detect_language\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Detect the blob's language using the Google Translate API.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03mRequires an internet connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m:rtype: str\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    592\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTextBlob.detext_translate is deprecated and will be removed in a future release. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse the official Google Translate API instead.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m\n\u001b[1;32m    596\u001b[0m )\n\u001b[0;32m--> 597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/textblob/translate.py:76\u001b[0m, in \u001b[0;36mTranslator.detect\u001b[0;34m(self, source, host, type_)\u001b[0m\n\u001b[1;32m     70\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: source}\n\u001b[1;32m     71\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{url}\u001b[39;00m\u001b[38;5;124m&sl=auto&tk=\u001b[39m\u001b[38;5;132;01m{tk}\u001b[39;00m\u001b[38;5;124m&client=\u001b[39m\u001b[38;5;132;01m{client}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     72\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m     73\u001b[0m     tk\u001b[38;5;241m=\u001b[39m_calculate_tk(source),\n\u001b[1;32m     74\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     75\u001b[0m )\n\u001b[0;32m---> 76\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m result, language \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m language\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/site-packages/textblob/translate.py:96\u001b[0m, in \u001b[0;36mTranslator._request\u001b[0;34m(self, url, host, type_, data)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m host \u001b[38;5;129;01mor\u001b[39;00m type_:\n\u001b[1;32m     95\u001b[0m     req\u001b[38;5;241m.\u001b[39mset_proxy(host\u001b[38;5;241m=\u001b[39mhost, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_)\n\u001b[0;32m---> 96\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m content \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/env23aug/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "TextBlob(\"War doesn't show who's right, sjust who's left.\").detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58241ac2-261d-42a4-84d7-3a92efff6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df1['lang'] = df1['text'].apply(lambda x: langid.classify(x)[0])\n",
    "print(df1.head())\n",
    "df1[df1['lang'] == 'en'].shape\n",
    "TextBlob(i).detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1ba9a-a5b3-4b3a-9256-de3fca8adac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9af3d591-0ef8-48d7-b13f-eeaec05a1efd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TODO: Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f3ebb-b50a-4dfd-99d9-7142ff29f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('data/nlp/gutenberg/metadata/metadata.csv')\n",
    "\n",
    "available_texts = list(os.listdir('data/nlp/gutenberg/data/text'))\n",
    "\n",
    "clean_meta = meta[~meta.author.isin({'Anonymous', 'Various'})]\n",
    "clean_meta = clean_meta[clean_meta.language.apply(lambda x: 'en' in x)]\n",
    "clean_meta = clean_meta[clean_meta.id.apply(lambda x: f'{x}_text.txt' in available_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a68fd7-28f2-416c-bcec-0a975f0d43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data_meta = book_data.merge(clean_meta, on=['id']).drop('type', axis=1).dropna()\n",
    "n_values = len(book_data_meta.author.unique())\n",
    "book_mapping = {k: v for k, v in zip(book_data_meta.author.unique(), range(n_values))}\n",
    "\n",
    "book_data_meta['id_2'] = book_data_meta.author.apply(lambda x: 'book_' + str(book_mapping[x]))\n",
    "book_data_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad0cfe-6f24-4bd9-a3f5-bc91b997cedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
